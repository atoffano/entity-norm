Une bonne représentation vectorielle d’un mot doit représenter au mieux son sens. Ainsi la représentation  vectorielle d’un mot doit être proche d’autres représentations vectorielles associées au contexte dans lequel survient le mot. Par exemple, “chien” devra avoir une représentation vectorielle proche de celle des mot "animal'', "jouer" et “nourrir”, ces mots étant souvent retrouvés dans le contexte d’utilisation du mot “chien”. Mais comment représenter un mot de telle manière à ce que sa représentation vectorielle ‘encode’ son sens ? L’idée est d'entraîner un modèle d’apprentissage sur des mots dans un texte. En entrée on fournit un mot du texte et on lui demande de prédire un autre mot rencontré dans le texte. A terme le modèle sera capable de donner à partir d’un mot une liste de probabilité de rencontrer chaque autre mot possible dans le texte.
